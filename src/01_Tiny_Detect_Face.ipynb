{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "from imutils.video import WebcamVideoStream\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pylab as pl\n",
    "import tensorflow as tf\n",
    "import util_tiny_face_detect\n",
    "import scipy.io\n",
    "from scipy.special import expit\n",
    "import tiny_face_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def overlay_bounding_boxes(raw_img, refined_bboxes, lw):\n",
    "#     \"\"\"\n",
    "#     Overlay bounding boxes of face on images\n",
    "#     Args:\n",
    "#         raw_img:\n",
    "#             A target image\n",
    "#         refined_bboxes:\n",
    "#             Bounding boxese of detected faces\n",
    "#         lw\n",
    "#             Line width of bounding boxes. If zero specified,\n",
    "#             this is determined based on confidence of each detection\n",
    "#     Returns:\n",
    "#         None.\n",
    "#     \"\"\"\n",
    "#     for r in refined_bboxes:\n",
    "#         # Normalization score [0-1]\n",
    "#         _score = expit(r[4])\n",
    "#         # score [0-255]\n",
    "#         cm_idx = int(np.ceil(_score * 255))\n",
    "#         rect_color = [int(np.ceil(x * 255)) for x in util_tiny_face_detect.cm_data[cm_idx]]\n",
    "#         _lw = lw\n",
    "#         if lw == 0:\n",
    "#             bw, bh = r[2] - r[0] + 1, r[3] - r[0] + 1\n",
    "#             _lw = 1 if min(bw, bh) <= 20 else max(2, min(3, min(bh / 20, bw / 20)))\n",
    "#             _lw = int(np.ceil(_lw * _score))\n",
    "            \n",
    "#             _r = [int(x) for x in r[:4]]\n",
    "#             cv2.rectangle(raw_img, (_r[0], _r[1]), (_r[2], _r[3]), rect_color, _lw)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "weight_file_path = \"../../../github/face/Tiny_Faces_in_Tensorflow/models/hr_res101.pkl\"\n",
    "prob_thresh = 0.5\n",
    "nms_thresh = 0.1\n",
    "line_width = 3\n",
    "MAX_INPUT_DIM = 5000.0\n",
    "font = cv2.FONT_HERSHEY_DUPLEX\n",
    "\n",
    "# Placeholder of input images. Currently batch size of one is supported\n",
    "x = tf.placeholder(tf.float32, [1, None, None, 3])\n",
    "model = tiny_face_model.Model(weight_file_path)\n",
    "score_final = model.tiny_face(x)\n",
    "\n",
    "average_image = model.get_data_by_key(\"average_image\")\n",
    "clusters = model.get_data_by_key(\"clusters\")\n",
    "clusters_h = clusters[:, 3] - clusters[:, 1] + 1\n",
    "clusters_w = clusters[:, 2] - clusters[:, 0] + 2\n",
    "normal_idx = np.where(clusters[:, 4] == 1)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_capture = cv2.VideoCapture('/home/damvantai/Downloads/20180801ГЛГlГTГУГXО┬Уc/2.avi')\n",
    "# frame_width = 1008\n",
    "# frame_height = 760\n",
    "# out = cv2.VideoWriter('output_tiny_face_camera_superviser.avi',cv2.VideoWriter_fourcc('M','J','P','G'), 10, (frame_width,frame_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(760, 1008, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/damvantai/.local/lib/python3.6/site-packages/ipykernel_launcher.py:15: MatplotlibDeprecationWarning: numpy.arange\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/damvantai/.local/lib/python3.6/site-packages/ipykernel_launcher.py:16: MatplotlibDeprecationWarning: numpy.arange\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "<class 'numpy.ndarray'>\n",
      "(0, 5)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'cv2.VideoWriter' object has no attribute 'imwrite'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-69613bed7aef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0mnumber_face\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"frame\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;36m0xFF\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'q'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'cv2.VideoWriter' object has no attribute 'imwrite'"
     ]
    }
   ],
   "source": [
    "# video_capture = WebcamVideoStream(src=0).start()\n",
    "number_face = 0\n",
    "while True:\n",
    "    ret, frame = video_capture.read()\n",
    "    print(frame.shape)\n",
    "#     frame = video_capture.read()\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame_float = frame.astype(np.float32)\n",
    "    \n",
    "    def _calc_scales():\n",
    "        raw_h, raw_w = frame.shape[0], frame.shape[1]\n",
    "        min_scale = min(np.floor(np.log2(np.max(clusters_w[normal_idx] / raw_w))),\n",
    "                        np.floor(np.log2(np.max(clusters_h[normal_idx] / raw_h))))\n",
    "        max_scale = min(1.0, -np.log2(max(raw_h, raw_w) / MAX_INPUT_DIM))\n",
    "        scales_down = pl.frange(min_scale, 0, 1.)\n",
    "        scales_up = pl.frange(0.5, max_scale, 0.5)\n",
    "        scales_pow = np.hstack((scales_down, scales_up))\n",
    "        scales = np.power(2.0, scales_pow)\n",
    "        return scales\n",
    "    \n",
    "    scales = _calc_scales()\n",
    "    bboxes = np.empty(shape=(0, 5))\n",
    "     # process input at different scales\n",
    "    for s in scales:\n",
    "#         print(\"Processing {} at scale {:.4f}\".format(fname, s))\n",
    "        img = cv2.resize(frame_float, (0, 0), fx=s, fy=s, interpolation=cv2.INTER_LINEAR)\n",
    "        img = img - average_image\n",
    "        img = img[np.newaxis, :]\n",
    "        \n",
    "        # we don't run every template on every scale ids of templates to ignore\n",
    "        tids = list(range(4, 12)) + ([] if s <= 1.0 else list(range(18, 25)))\n",
    "        ignoredTids = list(set(range(0, clusters.shape[0])) - set(tids))\n",
    "\n",
    "        # run through the net\n",
    "        score_final_tf = sess.run(score_final, feed_dict={x: img})\n",
    "\n",
    "        # collect scores\n",
    "        score_cls_tf, score_reg_tf = score_final_tf[:, :, :, :25], score_final_tf[:, :, :, 25:125]\n",
    "        prob_cls_tf = expit(score_cls_tf)\n",
    "        prob_cls_tf[0, :, :, ignoredTids] = 0.0\n",
    "\n",
    "        def _calc_bounding_boxes():\n",
    "            # threshold for detection\n",
    "            _, fy, fx, fc = np.where(prob_cls_tf > prob_thresh)\n",
    "\n",
    "            # interpret heatmap into bounding boxes\n",
    "            cy = fy * 8 - 1\n",
    "            cx = fx * 8 - 1\n",
    "            ch = clusters[fc, 3] - clusters[fc, 1] + 1\n",
    "            cw = clusters[fc, 2] - clusters[fc, 0] + 1\n",
    "\n",
    "            # extract bounding box refinement\n",
    "            Nt = clusters.shape[0]\n",
    "            tx = score_reg_tf[0, :, :, 0:Nt]\n",
    "            ty = score_reg_tf[0, :, :, Nt:2*Nt]\n",
    "            tw = score_reg_tf[0, :, :, 2*Nt:3*Nt]\n",
    "            th = score_reg_tf[0, :, :, 3*Nt:4*Nt]\n",
    "\n",
    "            # refine bounding boxes\n",
    "            dcx = cw * tx[fy, fx, fc]\n",
    "            dcy = ch * ty[fy, fx, fc]\n",
    "            rcx = cx + dcx\n",
    "            rcy = cy + dcy\n",
    "            rcw = cw * np.exp(tw[fy, fx, fc])\n",
    "            rch = ch * np.exp(th[fy, fx, fc])\n",
    "\n",
    "            scores = score_cls_tf[0, fy, fx, fc]\n",
    "            tmp_bboxes = np.vstack((rcx - rcw / 2, rcy - rch / 2, rcx + rcw / 2, rcy + rch / 2))\n",
    "            tmp_bboxes = np.vstack((tmp_bboxes / s, scores))\n",
    "            tmp_bboxes = tmp_bboxes.transpose()\n",
    "            return tmp_bboxes\n",
    "\n",
    "        tmp_bboxes = _calc_bounding_boxes()\n",
    "        bboxes = np.vstack((bboxes, tmp_bboxes)) # <class 'tuple'>: (5265, 5)\n",
    "\n",
    "\n",
    "#     print(\"time {:.2f} secs for {}\".format(time.time() - start, fname))\n",
    "\n",
    "    # non maximum suppression\n",
    "    # refind_idx = util.nms(bboxes, nms_thresh)\n",
    "    refind_idx = tf.image.non_max_suppression(tf.convert_to_tensor(bboxes[:, :4], dtype=tf.float32),\n",
    "                                               tf.convert_to_tensor(bboxes[:, 4], dtype=tf.float32),\n",
    "                                               max_output_size=bboxes.shape[0], iou_threshold=nms_thresh)\n",
    "    refind_idx = sess.run(refind_idx)\n",
    "    refined_bboxes = bboxes[refind_idx]\n",
    "    print(refined_bboxes)\n",
    "    print(type(refined_bboxes))\n",
    "    print(refined_bboxes.shape)\n",
    "#     overlay_bounding_boxes(frame, refined_bboxes, line_width)\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "    for (left, top, right, bottom, score) in refined_bboxes:\n",
    "        cv2.rectangle(frame, (int(left), int(top)), (int(right), int(bottom)), (0, 0, 255), 3)\n",
    "        cv2.putText(frame, str(score), (int(left) + 6, int(top) - 6), font, 1, (0, 0, 255))\n",
    "        face = frame[int(top):int(bottom), int(left):int(right)]\n",
    "#         filename = '../images/faces/%d.jpg'%d\n",
    "        cv2.imwrite(\"../images/faces/%d.jpg\"%number_face, face)\n",
    "        number_face += 1\n",
    "    cv2.imshow(\"frame\", frame)\n",
    "#     out.write(frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([[1, 2, 3, 4, 5], [3, 4, 5, 6, 7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (top, left, bottom, right, score) in a:\n",
    "    print(top, left)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plus(x, y):\n",
    "    return x + y + z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 1\n",
    "y = 2\n",
    "z = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plus(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dir(model))\n",
    "print(model.weight_file_path)\n",
    "print(model.tiny_face)\n",
    "print(model.get_data_by_key(\"average_image\"))\n",
    "print(model.get_data_by_key(\"clusters\"))\n",
    "clusters = model.get_data_by_key(\"clusters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
